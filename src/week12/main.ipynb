{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b1d9c854",
      "metadata": {
        "id": "b1d9c854"
      },
      "outputs": [],
      "source": [
        "#10.2 Transformer attention\n",
        "#10.2.1 Seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6ae5b052",
      "metadata": {
        "id": "6ae5b052"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c4841b42",
      "metadata": {
        "id": "c4841b42"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "58ebe3bd",
      "metadata": {
        "id": "58ebe3bd"
      },
      "outputs": [],
      "source": [
        "def normalizeString(df, lang):\n",
        "    sentence = df[lang].str.lower()\n",
        "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence\n",
        "\n",
        "def read_sentence(df, lang1, lang2):\n",
        "    sentence1 = normalizeString(df, lang1)\n",
        "    sentence2 = normalizeString(df, lang2)\n",
        "    return sentence1, sentence2\n",
        "\n",
        "def read_file(loc, lang1, lang2):\n",
        "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
        "    return df\n",
        "\n",
        "def process_data(lang1,lang2):\n",
        "    df = read_file('data/eng-fra.txt', lang1, lang2) #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요.\n",
        "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "\n",
        "    input_lang = Lang()\n",
        "    output_lang = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            input_lang.addSentence(sentence1[i])\n",
        "            output_lang.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f0c3e7a2",
      "metadata": {
        "id": "f0c3e7a2"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5cda608",
      "metadata": {
        "id": "e5cda608"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src).view(1,1,-1)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8c8c263c",
      "metadata": {
        "id": "8c8c263c"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.view(1, -1)\n",
        "        embedded = F.relu(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e32442e",
      "metadata": {
        "id": "2e32442e"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        input_length = input_lang.size(0)\n",
        "        batch_size = output_lang.shape[1]\n",
        "        target_length = output_lang.shape[0]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
        "\n",
        "        decoder_hidden = encoder_hidden.to(device)\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)\n",
        "\n",
        "        for t in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (output_lang[t] if teacher_force else topi)\n",
        "            if(teacher_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "93d4ebc3",
      "metadata": {
        "id": "93d4ebc3"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    model_optimizer.zero_grad()\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    output = model(input_tensor, target_tensor)\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9768b4e8",
      "metadata": {
        "id": "9768b4e8"
      },
      "outputs": [],
      "source": [
        "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(num_iteration)]\n",
        "\n",
        "    for iter in range(1, num_iteration+1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        total_loss_iterations += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            avarage_loss= total_loss_iterations / 5000\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, avarage_loss))\n",
        "\n",
        "    torch.save(model.state_dict(), f'mytraining.pt')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9bd2079f",
      "metadata": {
        "id": "9bd2079f"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "        decoded_words = []\n",
        "        output = model(input_tensor, output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('input {}'.format(pair[0]))\n",
        "        print('output {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted {}'.format(output_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6814115",
      "metadata": {
        "id": "b6814115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random sentence ['i left my guitar in your office.', \"j'ai laisse ma guitare dans ton bureau.\"]\n",
            "Input : 23191 Output : 39387\n",
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(39387, 256)\n",
            "  (gru): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n",
            "5000 5.0023\n",
            "10000 4.7611\n",
            "15000 4.7296\n",
            "20000 4.6757\n",
            "25000 4.6523\n",
            "30000 4.6630\n",
            "35000 4.6022\n",
            "40000 4.6017\n",
            "45000 4.5907\n",
            "50000 4.5845\n",
            "55000 4.5472\n",
            "60000 4.5747\n",
            "65000 4.5870\n",
            "70000 4.5813\n",
            "75000 4.5638\n"
          ]
        }
      ],
      "source": [
        "lang1 = 'eng'\n",
        "lang2 = 'fra'\n",
        "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 75000\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fa2807a7",
      "metadata": {
        "id": "fa2807a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input we have nothing to fear but fear itself.\n",
            "output on a rien a craindre sauf la peur elle-meme.\n",
            "predicted il ne a pas <EOS>\n",
            "input be kind to old people.\n",
            "output sois gentil envers les ainees.\n",
            "predicted il ne a pas <EOS>\n",
            "input are you staying for dinner?\n",
            "output restes-tu diner ?\n",
            "predicted il ne a pas\n",
            "input i do not drink coffee.\n",
            "output je ne bois pas de cafe.\n",
            "predicted il ne a pas <EOS>\n",
            "input that was all greek to me.\n",
            "output tout ca, c'etait du chinois pour moi.\n",
            "predicted il ne a pas <EOS>\n",
            "input after the revolution, france became a republic.\n",
            "output apres la revolution, la france devint une republique.\n",
            "predicted il ne a pas <EOS>\n",
            "input drop your weapons!\n",
            "output laissez tomber les armes !\n",
            "predicted il ne a pas <EOS>\n",
            "input i'm exhausted.\n",
            "output je suis creve.\n",
            "predicted il ne a pas\n",
            "input the clock stopped.\n",
            "output l'horloge s'arreta.\n",
            "predicted il ne a\n",
            "input no one really knows.\n",
            "output personne ne le sait vraiment.\n",
            "predicted il ne a pas <EOS>\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(model, input_lang, output_lang, pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6032888a",
      "metadata": {
        "id": "6032888a"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9bb7ef62",
      "metadata": {
        "id": "9bb7ef62"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            print_loss_avg = print_loss_total / 5000\n",
        "            print_loss_total = 0\n",
        "            print('%d,  %.4f' % (iter, print_loss_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6df879d6",
      "metadata": {
        "id": "6df879d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "AttnDecoderRNN(\n",
            "  (embedding): Embedding(39387, 512)\n",
            "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (gru): GRU(512, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            ")\n",
            "5000,  4.9032\n",
            "10000,  4.9264\n",
            "15000,  4.9404\n",
            "20000,  4.9195\n",
            "25000,  4.8941\n",
            "30000,  4.9494\n",
            "35000,  4.9297\n",
            "40000,  4.9096\n",
            "45000,  4.9182\n",
            "50000,  4.9208\n",
            "55000,  4.8930\n",
            "60000,  4.9150\n",
            "65000,  4.9109\n",
            "70000,  4.9130\n",
            "75000,  4.9163\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
        "\n",
        "print(encoder1)\n",
        "print(attn_decoder1)\n",
        "\n",
        "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
